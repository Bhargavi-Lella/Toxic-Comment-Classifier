# Toxic-Comment-Classifier
We have built a model that’s capable of detecting different types of toxicity like threats, obscenity, insults, and identity-based hate using NLP. We have used a dataset of comments from Wikipedia’s talk page edits.
The training dataset ia available at https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge
The test dataset is compressed into zip file and named as test.csv.zip in the repository.
The code is named as TCCcode.ipynb and the file format is ipynb.
